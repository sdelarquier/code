{
 "metadata": {
  "name": "SQLdev"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "sys.path.append('/davitpy')\n",
      "from pydarn import radar\n",
      "import sqlalchemy as sqla\n",
      "import psycopg2 as pg2\n",
      "import h5py\n",
      "from datetime import datetime, timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('id',) id\n",
        "(0, 2, ['tst', 'x'], u'Test Radar', u'JHUAPL', u'hdw.dat.tst', 0, '2008-02-03 00:00:00', '2500-01-01 00:00:00', 1)\n",
        "---key   -  id\n",
        "---tinds -  [0]\n",
        "--inds  -  [0]\n",
        "[ (0, 2, ['tst', 'x'], 'Test Radar', 'JHUAPL', 'hdw.dat.tst', 0, '2008-02-03 00:00:00', '2500-01-01 00:00:00', 1)] \n",
        "\n",
        "(1, 2, ['gbr', 'g'], u'Goose Bay', u'JHU/APL', u'hdw.dat.gbr', 1, '1983-10-01 00:00:00', '2500-01-01 00:00:00', 6)\n",
        "---key   -  id\n",
        "---tinds -  []\n",
        "--inds  -  [1]\n",
        "1\n",
        "pb here <type 'exceptions.TypeError'>\n",
        "Problem updating HDF5 file:  <type 'exceptions.SystemExit'>\n",
        "No module named plotUtils\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Create tables (drop existing first)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#engine = sqla.create_engine(\"postgresql://sd_dbwrite:more_dbwrite@sd-work8.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "engine = sqla.create_engine(\"postgresql:///radarInfo\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "# First drop the existing tables\n",
      "if engine.has_table(\"info\"):\n",
      "    infotb = sqla.Table(\"info\", meta, autoload=True)\n",
      "if engine.has_table(\"radars\"):\n",
      "    radartb = sqla.Table(\"radars\", meta, autoload=True)\n",
      "if engine.has_table(\"hdw\"):\n",
      "    hdwtb = sqla.Table(\"hdw\", meta, autoload=True)\n",
      "meta.drop_all()\n",
      "meta.clear()\n",
      "\n",
      "# Clean up database\n",
      "conn = pg2.connect(\"dbname=%s host=%s\" % ('radarInfo', 'localhost'))\n",
      "cursor = conn.cursor()\n",
      "old_isolation_level = conn.isolation_level\n",
      "conn.set_isolation_level(0)\n",
      "cursor.execute(\"VACUUM FULL ANALYZE;\")\n",
      "conn.commit()\n",
      "conn.set_isolation_level(old_isolation_level)\n",
      "\n",
      "# Then create the new tables\n",
      "infotb = sqla.Table( 'info', meta, \n",
      "                    sqla.Column('var', sqla.String, primary_key=True), \n",
      "                    sqla.Column('description', sqla.Text) , schema='public')\n",
      "infotb.create()\n",
      "\n",
      "radartb = sqla.Table( 'radars', meta, \n",
      "                     sqla.Column('id', sqla.Integer, primary_key=True), \n",
      "                     sqla.Column('cnum', sqla.Integer),\n",
      "                     sqla.Column('code', sqla.dialects.postgresql.ARRAY(sqla.String)), \n",
      "                     sqla.Column('name', sqla.String),\n",
      "                     sqla.Column('hdwfname', sqla.String), \n",
      "                     sqla.Column('operator', sqla.String),\n",
      "                     sqla.Column('status', sqla.Integer), \n",
      "                     sqla.Column('stTime', sqla.DateTime), \n",
      "                     sqla.Column('edTime', sqla.DateTime), \n",
      "                     sqla.Column('snum', sqla.Integer) , schema='public')\n",
      "radartb.create()\n",
      "\n",
      "hdwtb = sqla.Table( 'hdw', meta, \n",
      "                   sqla.Column('id', sqla.Integer, sqla.ForeignKey('public.radars.id', schema='public'), primary_key=True), \n",
      "                   sqla.Column('tval', sqla.DateTime, primary_key=True), \n",
      "                   sqla.Column('geolat', sqla.Float),\n",
      "                   sqla.Column('geolon', sqla.Float),\n",
      "                   sqla.Column('alt', sqla.Float),\n",
      "                   sqla.Column('boresite', sqla.Float),\n",
      "                   sqla.Column('bmsep', sqla.Float),\n",
      "                   sqla.Column('vdir', sqla.Integer), \n",
      "                   sqla.Column('atten', sqla.Float),\n",
      "                   sqla.Column('tdiff', sqla.Float),\n",
      "                   sqla.Column('phidiff', sqla.Float),\n",
      "                   sqla.Column('interfer', sqla.dialects.postgresql.ARRAY(sqla.Float)),\n",
      "                   sqla.Column('recrise', sqla.Float),\n",
      "                   sqla.Column('maxatten', sqla.Integer), \n",
      "                   sqla.Column('maxgate', sqla.Integer), \n",
      "                   sqla.Column('maxbeam', sqla.Integer) , schema='public' )\n",
      "hdwtb.create()\n",
      "\n",
      "# Set permission\n",
      "conn = engine.connect()\n",
      "res_grant = conn.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA public TO sd_dbread; COMMIT;\")\n",
      "res_grant = conn.execute(\"GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO sd_dbwrite; COMMIT;\")\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Generate list of dictionnarie to insert"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "radars = []\n",
      "hdw = []\n",
      "radarF = radar.radarRead()\n",
      "nradar = len(radarF['id'])\n",
      "for irad in xrange( nradar ):\n",
      "    radars.append( {'id': radarF['id'][irad], \n",
      "                    'cnum': radarF['cnum'][irad], \n",
      "                    'code': radarF['code'][irad], \n",
      "                    'name': radarF['name'][irad], \n",
      "                    'operator': radarF['operator'][irad], \n",
      "                    'hdwfname': radarF['hdwfname'][irad], \n",
      "                    'status': radarF['status'][irad], \n",
      "                    'stTime': radarF['stTime'][irad], \n",
      "                    'edTime': radarF['edTime'][irad], \n",
      "                    'snum': 0} )\n",
      "    siteF = radar.hdwRead(radars[-1]['hdwfname'])\n",
      "    if not siteF: continue\n",
      "    tsnum = 0\n",
      "    for isit in xrange( len(siteF['tval']) ):\n",
      "        if siteF['tval'][isit] == 0: continue\n",
      "        tval = datetime(3000,1,1) if siteF['tval'][isit] == -1 else siteF['tval'][isit]\n",
      "        hdw.append( {'id': radarF['id'][irad], \n",
      "                   'tval': tval,\n",
      "                   'geolat': siteF['geolat'][isit],\n",
      "                   'geolon': siteF['geolon'][isit],\n",
      "                   'alt': siteF['alt'][isit], \n",
      "                   'boresite': siteF['boresite'][isit],\n",
      "                   'bmsep': siteF['bmsep'][isit],\n",
      "                   'vdir': siteF['vdir'][isit],\n",
      "                   'atten': siteF['atten'][isit],\n",
      "                   'tdiff': siteF['tdiff'][isit],\n",
      "                   'phidiff': siteF['phidiff'][isit],\n",
      "                   'interfer': siteF['interfer'][isit],\n",
      "                   'recrise': siteF['recrise'][isit],\n",
      "                   'maxatten': siteF['maxatten'][isit],\n",
      "                   'maxgate': siteF['maxgate'][isit],\n",
      "                   'maxbeam': siteF['maxbeam'][isit]} )\n",
      "        tsnum += 1\n",
      "    radars[-1]['snum'] = tsnum\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Insert into tables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = sqla.create_engine(\"postgresql://sd_dbwrite:more_dbwrite@sd-data.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "radartb = sqla.Table(\"radars\", meta, autoload=True)\n",
      "hdwtb = sqla.Table(\"hdw\", meta, autoload=True)\n",
      "\n",
      "# create connection object\n",
      "conn = engine.connect()\n",
      "\n",
      "# create an Insert object\n",
      "radarIns = radartb.insert()\n",
      "hdwIns = hdwtb.insert()\n",
      "\n",
      "# execute\n",
      "res_radar = conn.execute(radarIns, radars)\n",
      "res_hdw = conn.execute(hdwIns, hdw)\n",
      "\n",
      "# close\n",
      "res_radar.close()\n",
      "res_hdw.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OperationalError",
       "evalue": "(OperationalError) could not connect to server: Connection refused\n\tIs the server running on host \"sd-work8.ece.vt.edu\" (128.173.144.40) and accepting\n\tTCP/IP connections on port 5432?\n None None",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-5e149a2a6cb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetaData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mradartb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"radars\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mhdwtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hdw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/schema.pyc\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kw)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_parent_attach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/schema.pyc\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, name, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# circular foreign keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mautoload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autoload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoload_with\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;31m# initialize all the column, etc. objects.  done after reflection to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/schema.pyc\u001b[0m in \u001b[0;36m_autoload\u001b[1;34m(self, metadata, autoload_with, include_columns)\u001b[0m\n\u001b[0;32m    375\u001b[0m             bind.run_callable(\n\u001b[0;32m    376\u001b[0m                     \u001b[0mbind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreflecttable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m                 )\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mrun_callable\u001b[1;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2273\u001b[0m         \"\"\"\n\u001b[1;32m-> 2274\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2275\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2276\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mcontextual_connect\u001b[1;34m(self, close_with_result, **kwargs)\u001b[0m\n\u001b[0;32m   2338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2339\u001b[0m         return self._connection_cls(self, \n\u001b[1;32m-> 2340\u001b[1;33m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2341\u001b[0m                                     \u001b[0mclose_with_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2342\u001b[0m                                     **kwargs)\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \"\"\"\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_threadlocal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_echo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_echo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_log_debug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m             \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             rec.fairy = weakref.ref(\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m_do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                 \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overflow\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;34m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created new connection %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/engine/strategies.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                     \u001b[1;31m# Py3K\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_connect_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/dist-packages/psycopg2/__init__.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(dsn, database, user, password, host, port, connection_factory, async, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     return _connect(dsn,\n\u001b[1;32m--> 179\u001b[1;33m         connection_factory=connection_factory, async=async)\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mOperationalError\u001b[0m: (OperationalError) could not connect to server: Connection refused\n\tIs the server running on host \"sd-work8.ece.vt.edu\" (128.173.144.40) and accepting\n\tTCP/IP connections on port 5432?\n None None"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Insert metadata into INFO table"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infodict = [{'var': 'id' ,  'description': 'unique radar ID (int)'}, \n",
      "            {'var': 'cnum' ,  'description': 'number of radar codes (int)'}, \n",
      "            {'var': 'code' ,  'description': 'radar codes, , i.e. [gbr, g] (list of strings)'}, \n",
      "            {'var': 'name' ,  'description': 'radar full name (string)'}, \n",
      "            {'var': 'operator' ,  'description': 'radar operator (string)'}, \n",
      "            {'var': 'hdwfname' ,  'description': 'hdw.dat file name, usually hdw.dat.code (string)'}, \n",
      "            {'var': 'status' ,  'description': 'radar operating status: 1 for active, -1 for inactive and 0 for planned (int)'}, \n",
      "            {'var': 'stTime' ,  'description': 'radar first light (string: %Y-%m-%d %H:%M:%S)'}, \n",
      "            {'var': 'edTime' ,  'description': 'radar last day of operation (string: %Y-%m-%d %H:%M:%S)'}, \n",
      "            {'var': 'snum' ,  'description': 'number of site updates, i.e. entries in hdw.dat (int)'}, \n",
      "            {'var': 'tval' ,  'description': 'last date/time operating with given parameters; 3000/1/1 if current (string: %Y-%m-%d %H:%M:%S)'}, \n",
      "            {'var': 'geolat' ,  'description': 'main array geographic latitude (float) [degrees]'}, \n",
      "            {'var': 'geolon' ,  'description': 'main array geographic longitude (float) [degrees]'}, \n",
      "            {'var': 'alt' ,  'description': 'main array altitude (float) [km]'}, \n",
      "            {'var': 'boresite' ,  'description': 'boresight azimuth (float) [degrees]'}, \n",
      "            {'var': 'bmsep' ,  'description': 'beam separation (float) [degrees]'}, \n",
      "            {'var': 'vdir' ,  'description': 'velocity sign: (int) \\\n",
      "At the radar level, backscattered signals with frequencies above the \\\n",
      "transmitted frequency are assigned positive Doppler velocities while \\\n",
      "backscattered signals with frequencies below the transmitted frequency \\\n",
      "are assigned negative Doppler velocity. This convention can be reversed \\\n",
      "by changes in receiver design or in the data samping rate. This parameter \\\n",
      "is set to +1 or -1 to maintain the convention.'}, \n",
      "            {'var': 'atten' ,  'description': 'Analog Rx attenuator step (float) [dB]'}, \n",
      "            {'var': 'tdiff' ,  'description': '(float) [microsecond] \\\n",
      "Propagation time from interferometer array antenna to \\\n",
      "phasing matrix input minus propagation time from main array antenna \\\n",
      "through transmitter to phasing matrix input. If the signal from the \\\n",
      "interferometer comes first, then tdiff < 0'}, \n",
      "            {'var': 'phidiff' ,  'description': '(float) \\\n",
      "Phase sign (Cabling errors can lead to a 180 degree shift of the \\\n",
      "interferometry phase measurement. +1 indicates that the sign is \\\n",
      "correct, -1 indicates that it must be flipped.)'}, \n",
      "            {'var': 'interfer' ,  'description': 'Interferometer offset  (Displacement of midpoint of \\\n",
      "interferometer array from midpoint of main array. This is given in \\\n",
      "meters in Cartesian coordinates. X is along the line of antennas with \\\n",
      "+X toward higher antenna numbers, Y is along the array normal \\\n",
      "direction with +Y in the direction of the array normal. Z is the \\\n",
      "altitude difference, +Z up.)'}, \n",
      "            {'var': 'recrise' ,  'description': '''Analog Rx rise time (float) [microsecond]\n",
      "Time delays of less than ~10 microseconds can be ignored. If narrow-band filters are \n",
      "used in analog receivers or front-ends, the time delays should be specified.'''}, \n",
      "            {'var': 'maxatten' ,  'description': 'Analog attenuation stages (int) \\\n",
      "Number of stages. This is used for gain control of an analog receiver or front-end.'}, \n",
      "            {'var': 'maxgate' ,  'description': 'Maximum number of range gates (int)'}, \n",
      "            {'var': 'maxbeam' ,  'description': 'Maximum number of beams (int)'} ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = sqla.create_engine(\"postgresql://sd_dbwrite:more_dbwrite@sd-work8.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "infotb = sqla.Table(\"info\", meta, autoload=True)\n",
      "\n",
      "# create an Insert object\n",
      "conn = engine.connect()\n",
      "infoIns = infotb.insert()\n",
      "res_info = conn.execute(infoIns, infodict)\n",
      "res_info.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Read from postgreSQL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#engine = sqla.create_engine(\"postgresql://sd_dbread:@sd-work8.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "engine = sqla.create_engine(\"postgresql://sd_dbread:@sd-data.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "radartb = sqla.Table(\"radars\", meta, autoload=True)\n",
      "hdwtb = sqla.Table(\"hdw\", meta, autoload=True)\n",
      "infotb = sqla.Table(\"info\", meta, autoload=True)\n",
      "\n",
      "radarsSel = radartb.select().execute().fetchall()\n",
      "hdwSel = hdwtb.select().execute().fetchall()\n",
      "infoSel = infotb.select().execute().fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Fill hdf5 file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Date format\n",
      "dtfmt = '%Y-%m-%d %H:%M:%S'\n",
      "dttest = datetime.utcnow().strftime(dtfmt)\n",
      "# Remove file (if it exists)\n",
      "os.remove(radar.__path__[0]+'/radars.hdf5')\n",
      "\n",
      "# Open file\n",
      "f = h5py.File(radar.__path__[0]+'/radars.hdf5','w')\n",
      "\n",
      "dtype_rad = numpy.dtype([('id', 'i'), \n",
      "                         ('cnum', 'i'),\n",
      "                         ('code', 'S3', (2,)),\n",
      "                         ('name', h5py.new_vlen(str) ), \n",
      "                         ('operator', h5py.new_vlen(str) ), \n",
      "                         ('hdwfname', h5py.new_vlen(str) ), \n",
      "                         ('status', 'i'), \n",
      "                         ('stTime', 'S{}'.format(len(dttest))), \n",
      "                         ('edTime', 'S{}'.format(len(dttest))), \n",
      "                         ('snum', 'i') ])\n",
      "rad_ds = f.create_dataset('radar', (1,), dtype=dtype_rad, maxshape=(None,))\n",
      "\n",
      "\n",
      "dtype_hdw = numpy.dtype([('id', 'i'), \n",
      "                         ('tval', 'S{}'.format(len(dttest))),\n",
      "                         ('geolat', 'float'),\n",
      "                         ('geolon', 'float'),\n",
      "                         ('alt', 'float'),\n",
      "                         ('boresite', 'float'),\n",
      "                         ('bmsep', 'float'),\n",
      "                         ('vdir', 'i'),\n",
      "                         ('tdiff', 'float'),\n",
      "                         ('phidiff', 'float'),\n",
      "                         ('recrise', 'float'),\n",
      "                         ('atten', 'float'),\n",
      "                         ('maxatten', 'float'),\n",
      "                         ('maxgate', 'i'),\n",
      "                         ('maxbeam', 'i'),\n",
      "                         ('interfer', numpy.float64, (3,)) ])\n",
      "hdw_ds = f.create_dataset('hdw', (1,), dtype=dtype_hdw, maxshape=(None,))\n",
      "\n",
      "dtype_info = numpy.dtype([('var', h5py.new_vlen(str)),\n",
      "                          ('description', h5py.new_vlen(str)) ])\n",
      "info_ds = f.create_dataset(\"metadata\", (1,), dtype=dtype_info, maxshape=(None,))\n",
      "\n",
      "# Close file\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Update hdf5 file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sqlaToArr(sel, dtype=dtype):\n",
      "    arr = numpy.empty(len(sel), dtype=dtype)\n",
      "    for ir,row in enumerate(sel):\n",
      "        for k,v in row.items():\n",
      "            try:\n",
      "                arr[ir][k] = v\n",
      "            except (ValueError, TypeError):\n",
      "                arr[ir][k][:] = v\n",
      "    return arr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_rad = sqlaToArr(radarsSel, dtype_rad)\n",
      "arr_hdw = sqlaToArr(hdwSel, dtype_hdw)\n",
      "arr_info = sqlaToArr(infoSel, dtype_info)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Date format\n",
      "dtfmt = '%Y-%m-%d %H:%M:%S'\n",
      "\n",
      "# Open file\n",
      "f = h5py.File(radar.__path__[0]+'/radars.hdf5','r+')\n",
      "\n",
      "# Acquire datasets (due to a bug in h5py 2.0, we cannot write directly to f['dset'])\n",
      "rad_ds = f['radar']\n",
      "hdw_ds = f['hdw']\n",
      "info_ds = f['metadata']\n",
      "\n",
      "if hdw_ds.shape != arr_hdw.shape: hdw_ds.resize(arr_hdw.shape)\n",
      "if info_ds.shape != arr_info.shape: info_ds.resize(arr_info.shape)\n",
      "\n",
      "for rad in arr_rad:\n",
      "    inds = where( rad_ds[:,'id']==rad['id'] )\n",
      "    try:\n",
      "        rad_ds[inds[0][0]] = rad\n",
      "    except IndexError:\n",
      "        rad_ds.resize((rad_ds.shape[0]+1,))\n",
      "        rad_ds[rad_ds.shape[0]-1] = rad\n",
      "\n",
      "hdw_ds[:] = arr_hdw\n",
      "info_ds[:] = arr_info\n",
      "\n",
      "# Close file\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Test populating class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class testNetwork(object):\n",
      "    def __init__(self):\n",
      "        self.info = []\n",
      "        # Open file\n",
      "        f = h5py.File(radar.__path__[0]+'/radars.hdf5','r')\n",
      "        radarF = f['/radar']\n",
      "        self.nradar = len(radarF['id'])\n",
      "        for irad in range( self.nradar ):\n",
      "            tRadar = radar.radar()\n",
      "            tRadar.id = radarF['id'][irad]\n",
      "            tRadar.status = radarF['status'][irad]\n",
      "            tRadar.cnum = radarF['cnum'][irad]\n",
      "            tRadar.stTime = datetime.strptime(radarF['stTime'][irad], dtfmt)\n",
      "            tRadar.edTime = datetime.strptime(radarF['edTime'][irad], dtfmt)\n",
      "            tRadar.name = radarF['name'][irad]\n",
      "            tRadar.operator = radarF['operator'][irad]\n",
      "            tRadar.hdwfname = radarF['hdwfname'][irad]\n",
      "            tRadar.code = radarF['code'][irad]\n",
      "            # Then, load info from hdw.dat file\n",
      "            siteF = f['/hdw']\n",
      "            siteInds = where( siteF['id'][:] == tRadar.id )[0]\n",
      "            if siteInds == []: continue\n",
      "            tsnum = 0\n",
      "            for ist,isit in enumerate(siteInds):\n",
      "                tRadar.site[ist].tval = datetime.strptime(siteF['tval'][isit], dtfmt)\n",
      "                tRadar.site[ist].geolat = siteF['geolat'][isit]\n",
      "                tRadar.site[ist].geolon = siteF['geolon'][isit]\n",
      "                tRadar.site[ist].alt = siteF['alt'][isit]\n",
      "                tRadar.site[ist].boresite = siteF['boresite'][isit]\n",
      "                tRadar.site[ist].bmsep = siteF['bmsep'][isit]\n",
      "                tRadar.site[ist].vdir = siteF['vdir'][isit]\n",
      "                tRadar.site[ist].atten = siteF['atten'][isit]\n",
      "                tRadar.site[ist].tdiff = siteF['tdiff'][isit]\n",
      "                tRadar.site[ist].phidiff = siteF['phidiff'][isit]\n",
      "                tRadar.site[ist].interfer = siteF['interfer'][isit]\n",
      "                tRadar.site[ist].recrise = siteF['recrise'][isit]\n",
      "                tRadar.site[ist].maxatten = siteF['maxatten'][isit]\n",
      "                tRadar.site[ist].maxgate = siteF['maxgate'][isit]\n",
      "                tRadar.site[ist].maxbeam = siteF['maxbeam'][isit]\n",
      "                tsnum += 1\n",
      "            tRadar.snum = tsnum\n",
      "            self.info.append(tRadar)\n",
      "        f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rads = testNetwork()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Test implementation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pydarn.plot as sdplot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(10,10))\n",
      "myMap = sdplot.map(boundingLat=30.)\n",
      "sdplot.overlayRadar(myMap, all=True)\n",
      "sdplot.overlayFov(myMap, codes=radar.network().getAllCodes(hemi='north'), hemi='north', maxGate=70)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###RBSP database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#engine = sqla.create_engine(\"postgresql://sd_dbwrite:more_dbwrite@sd-data.ece.vt.edu:5432/radarInfo?sslmode=require\")\n",
      "engine = sqla.create_engine(\"postgresql:///rbsp\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "# First drop the existing tables\n",
      "if engine.has_table(\"orbit\"):\n",
      "    tb_orbit = sqla.Table(\"orbit\", meta, autoload=True)\n",
      "if engine.has_table(\"footpoint\"):\n",
      "    tb_footpoint = sqla.Table(\"footpoint\", meta, autoload=True)\n",
      "if engine.has_table(\"apogee\"):\n",
      "    tb_apogee = sqla.Table(\"apogee\", meta, autoload=True)\n",
      "meta.drop_all()\n",
      "meta.clear()\n",
      "\n",
      "# Clean up database\n",
      "conn = pg2.connect(\"dbname=%s host=%s\" % ('radarInfo', 'localhost'))\n",
      "cursor = conn.cursor()\n",
      "old_isolation_level = conn.isolation_level\n",
      "conn.set_isolation_level(0)\n",
      "cursor.execute(\"VACUUM FULL ANALYZE;\")\n",
      "conn.commit()\n",
      "conn.set_isolation_level(old_isolation_level)\n",
      "\n",
      "# Then create the new tables\n",
      "'''\n",
      "tb_orbit = sqla.Table( 'orbit', meta, \n",
      "                    sqla.Column('time', sqla.DateTime, primary_key=True), \n",
      "                    sqla.Column('sat', sqla.String, primary_key=True), \n",
      "                    sqla.Column('lat', sqla.Float),  \n",
      "                    sqla.Column('lon', sqla.Float),  \n",
      "                    sqla.Column('alt', sqla.Float) , schema='public')\n",
      "tb_orbit.create()'''\n",
      "\n",
      "tb_footpoint = sqla.Table( 'footpoint', meta, \n",
      "                    sqla.Column('time', sqla.DateTime, primary_key=True), \n",
      "                    sqla.Column('sat', sqla.String, primary_key=True), \n",
      "                    sqla.Column('latN', sqla.Float),  \n",
      "                    sqla.Column('lonN', sqla.Float),  \n",
      "                    sqla.Column('latS', sqla.Float),  \n",
      "                    sqla.Column('lonS', sqla.Float), schema='public')\n",
      "tb_footpoint.create()\n",
      "\n",
      "'''\n",
      "tb_apogee = sqla.Table( 'apogee', meta, \n",
      "                    sqla.Column('time', sqla.DateTime, sqla.ForeignKey('public.orbit.time', schema='public'), primary_key=True), \n",
      "                    sqla.Column('sat', sqla.String, primary_key=True), \n",
      "                    sqla.Column('lat', sqla.Float),  \n",
      "                    sqla.Column('lon', sqla.Float),  \n",
      "                    sqla.Column('alt', sqla.Float) , schema='public')\n",
      "tb_apogee.create()'''\n",
      "\n",
      "# Set permission\n",
      "conn = engine.connect()\n",
      "res_grant = conn.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA public TO sd_dbread; COMMIT;\")\n",
      "res_grant = conn.execute(\"GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO sd_dbwrite; COMMIT;\")\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tsyganenko as ts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select a date\n",
      "date = datetime(2012,8,30)\n",
      "tdate = timedelta(days=1)\n",
      "while date < datetime(2013,3,1):\n",
      "    traceA = ts.tsygTrace(filename='../rbsp/data/trace.{}.A.dat'.format(date.strftime('%Y%m%d')))\n",
      "    traceB = ts.tsygTrace(filename='../rbsp/data/trace.{}.B.dat'.format(date.strftime('%Y%m%d')))\n",
      "    \n",
      "    fp = []\n",
      "    for ipt in xrange(len(traceA.lat)):\n",
      "        fp.append( {'time': traceA.datetime[ipt], \n",
      "                    'sat': 'A', \n",
      "                    'latN': traceA.latNH[ipt], \n",
      "                    'lonN': traceA.lonNH[ipt], \n",
      "                    'latS': traceA.latSH[ipt], \n",
      "                    'lonS': traceA.lonSH[ipt]} )\n",
      "    for ipt in xrange(len(traceB.lat)):\n",
      "        fp.append( {'time': traceB.datetime[ipt], \n",
      "                    'sat': 'B', \n",
      "                    'latN': traceB.latNH[ipt], \n",
      "                    'lonN': traceB.lonNH[ipt], \n",
      "                    'latS': traceB.latSH[ipt], \n",
      "                    'lonS': traceB.lonSH[ipt]} )\n",
      "        \n",
      "    # create connection object\n",
      "    conn = engine.connect()\n",
      "    # Rm duplicates\n",
      "    for f in fp:\n",
      "        res_del = conn.execute( tb_footpoint.delete().where(tb_footpoint.c.time==f['time'] and tb_footpoint.c.sat==f['sat']) )\n",
      "    # create an Insert object\n",
      "    ins_footpoint = tb_footpoint.insert()\n",
      "    # execute\n",
      "    res_footpoint = conn.execute(ins_footpoint, fp)\n",
      "    # close\n",
      "    res_footpoint.close()\n",
      "    conn.close()\n",
      "    \n",
      "    date += tdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = sqla.create_engine(\"postgresql:///rbsp\")\n",
      "meta = sqla.MetaData(engine)\n",
      "\n",
      "tb_footpoint = sqla.Table(\"footpoint\", meta, autoload=True)\n",
      "\n",
      "sel_fp = tb_footpoint.select().order_by(tb_footpoint.c.time).execute().fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('/home/sebastien/Desktop/rbspFp.dat', 'w')\n",
      "for row in sel_fp:\n",
      "    line = '{:>4d} {:>2d} {:>2d} {:>2d} {:>2d} {} {: >6.2f} {: >6.2f} {: >6.2f} {: >6.2f}\\n'.format(\n",
      "                     row.time.year, \n",
      "                     row.time.month, \n",
      "                     row.time.day, \n",
      "                     row.time.hour, \n",
      "                     row.time.minute, \n",
      "                     row.sat, \n",
      "                     row.latN, \n",
      "                     row.lonN, \n",
      "                     row.latS, \n",
      "                     row.lonS )\n",
      "    f.write(line)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}